# ğŸ­ Garment Factory Productivity â€“ EDA & ANN Regression

This project analyzes a real-world garment production dataset and builds **Artificial Neural Network (ANN)** models to predict each teamâ€™s **productivity score**. It walks through the full pipeline: data loading, EDA, feature engineering, scaling, modeling (Sequential & Functional ANN), and evaluation with regression metrics.

---

## ğŸ¯ Objectives

* Explore how operational factors relate to productivity
* Engineer features from dates and categories
* Train and compare **Sequential vs Functional** ANN architectures
* Evaluate models with **MSE, RMSE, and RÂ²**
* Select the best-performing model for reporting

---

## ğŸ—‚ï¸ Dataset

Each row is a teamâ€“day observation.

* `date` â€” Date of assessment
* `day` â€” Day of week
* `quarter` â€” Quarter of year (`Quarter1â€“Quarter4`)
* `Team Code` â€” Team identifier
* `smv` â€” Standard Minute Value (allocated time per task)
* `wip` â€” Work-in-progress units
* `over_time` â€” Overtime minutes
* `incentive` â€” Incentive (USD)
* `idle_time` â€” Idle minutes
* `idle_men` â€” Number of idle workers
* `no_of_style_change` â€” Style change count
* `no_of_workers` â€” Team size
* `productivity_score` â€” **Target** (percentage, typically 0â€“1)

---

## ğŸ§¹ Data Preparation

### Outliers

* Inspected via histograms and boxplots.
* **Kept** (considered operationally reasonable).

### Feature Engineering

* **Date split** (derived components as needed).
* **Manual encoding for `day`** (ordinal).
* **One-hot encoding for `Team Code`** (and relevant categoricals).

### Train/Test Split & Scaling

* **Split before scaling** to avoid leakage.
* **RobustScaler** applied to features (robust to heavy tails).

---

## ğŸ“Š Exploratory Data Analysis (EDA)

* **Distributions** for numeric variables (e.g., `over_time`, `idle_time`, `wip`, `smv`, `incentive`).
* **Boxplots of `productivity_score`** against all variables.
* **Correlation heatmap** among numeric features and `productivity_score`.

---

## ğŸ§  Modeling

### Models

* **ANN â€“ Sequential API**
* **ANN â€“ Functional API**
* Both base versions were **modified** (architecture/regularization tweaks).
* **Best model:** **Modified Sequential ANN** (selected by test-set metrics).

### Training Setup

* Loss: **MSE**
* Optimizer: (e.g., **Adam**, per notebook)
* Early stopping / callbacks as configured in the notebook
* Reproducible splits with fixed random state

---

## ğŸ“ˆ Evaluation

**Metrics:** **MSE**, **RMSE**, **RÂ²**.
**Comparison:** Sequential (base) vs Functional (base) vs **Modified Sequential** vs Modified Functional.
The **Modified Sequential ANN** achieved the **lowest MSE/RMSE** and **highest RÂ²** on the test set.
(See notebook outputs for exact values.)

---

## ğŸ“Œ Conclusion

* Outliers **kept**; **RobustScaler** mitigated heavy-tailed features.
* EDA focused on **distributions**, **boxplots vs productivity**, and **correlation heatmap**.
* Features: **date split**, **manual `day` encoding**, **one-hot `Team Code`**.
* **Train/test split before scaling** to prevent leakage.
* Compared **Sequential vs Functional** ANN (base + modified).
* **Modified Sequential ANN** delivered the **best MSE/RMSE/RÂ²** on the test set.
